{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ktuna/Projects/env/lib/python3.12/site-packages (4.46.2)\n",
      "Requirement already satisfied: torch in /Users/ktuna/Projects/env/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/ktuna/Projects/env/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: filelock in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ktuna/Projects/env/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip3 install transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 2: Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available, else fallback to MPS or CPU\n",
    "# device = \"gpu\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text generation pipeline\n",
    "generator = pipeline('text-generation', model='gpt2', device=device)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Create input text box and output display area\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter text here',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(overflow_x = 'auto', display= 'inline-flex', flex_flow= 'row wrap')\n",
    ")\n",
    "\n",
    "# Style the button to be green\n",
    "generate_button = widgets.Button(\n",
    "    description=\"Generate Text\",\n",
    "    button_style='', # Setting to '' allows custom CSS\n",
    "    layout=widgets.Layout(width=\"20%\")\n",
    ")\n",
    "generate_button.style.button_color = 'lightgreen'  # This sets a light green color to the button\n",
    "\n",
    "text_output = widgets.Output(layout=widgets.Layout(overflow_x = 'auto', display= 'inline-flex', flex_flow= 'row wrap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle text generation when the button is clicked\n",
    "def text_button_click(b):\n",
    "    prompt = text_input.value\n",
    "    \n",
    "    # Encode the input and move it to the selected device\n",
    "    inputs = generator.tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "    inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "\n",
    "    # Generate text with attention_mask and pad_token_id\n",
    "    generated_texts = generator.model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        num_beams=3,\n",
    "        repetition_penalty=2.0,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=1, \n",
    "        pad_token_id=generator.tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated texts\n",
    "    decoded_texts = [generator.tokenizer.decode(gen, skip_special_tokens=True) for gen in generated_texts]\n",
    "    \n",
    "    # Clear previous output and display new results\n",
    "    with text_output:\n",
    "        text_output.clear_output()\n",
    "        for i, gen_text in enumerate(decoded_texts):\n",
    "            print(f\"Generated Text {i+1}: {gen_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a146d598d415fa98a87fbe051118e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Input:', layout=Layout(display='inline-flex', flex_flow='row wrap'), placeholder='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1587f738c3df4d518b9f07fecf518ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', layout=Layout(width='20%'), style=ButtonStyle(button_color='lightgreen'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b7f337a68a484eb7f77572026788fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='inline-flex', flex_flow='row wrap'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach the button click event\n",
    "generate_button.on_click(text_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, generate_button, text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astro GPT: A fine-tuned version of GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/astroGPT\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stevhliu/astroGPT\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "# Create input text box and output display area\n",
    "zodiac_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter date here (exp, Sep 02, 2020)',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(overflow_x = 'auto', display= 'inline-flex', flex_flow= 'row wrap')\n",
    ")\n",
    "\n",
    "# Style the button to be green\n",
    "horoscope_button = widgets.Button(\n",
    "    description=\"Generate Horoscope\",\n",
    "    button_style='', # Setting to '' allows custom CSS\n",
    "    layout=widgets.Layout(width=\"20%\")\n",
    ")\n",
    "horoscope_button.style.button_color = 'lightgreen'  # This sets a light green color to the button\n",
    "\n",
    "zodiac_output = widgets.Output(layout=widgets.Layout(overflow_x = 'auto', display= 'inline-flex', flex_flow= 'row wrap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle text generation when the button is clicked\n",
    "def zodiac_button_click(b):\n",
    "    prompt = zodiac_input.value\n",
    "    \n",
    "    # Encode the input and move it to the selected device\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate text with attention_mask and pad_token_id\n",
    "    sample_output = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        num_beams=3,\n",
    "        repetition_penalty=2.0,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=1, \n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # Decode the output tokens to get the text\n",
    "    generated_text = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Clear previous output and display new results\n",
    "    with zodiac_output:\n",
    "        zodiac_output.clear_output()\n",
    "        print(f\"Generated Text: {generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e5285ae86e455aabc0bec6d7d1fedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Input:', layout=Layout(display='inline-flex', flex_flow='row wrap'), placeholder='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a0f5a8b25343bfbf2d869300211c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Horoscope', layout=Layout(width='20%'), style=ButtonStyle(button_color='lightgree…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdedf3cd3d48b8bdd52b59dcf0b049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='inline-flex', flex_flow='row wrap'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach the button click event\n",
    "horoscope_button.on_click(zodiac_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(zodiac_input, horoscope_button, zodiac_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_lecture",
   "language": "python",
   "name": "llm_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
